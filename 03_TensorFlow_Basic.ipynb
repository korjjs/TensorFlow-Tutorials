{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 - TensorFlow Basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqJTQwzRwgZJo//eI9eEhH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korjjs/TensorFlow-Tutorials/blob/master/03_TensorFlow_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvshftTsajO4",
        "outputId": "e8d90de3-4b2f-472b-867b-9affd3ebf040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# 텐서플로우의 기본적인 구성을 익힙니다.\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# tf.constant: 말 그대로 상수입니다.\n",
        "hello = tf.constant('Hello, TensorFlow!')\n",
        "print(hello)\n",
        "\n",
        "a = tf.constant(10)\n",
        "b = tf.constant(32)\n",
        "c = tf.add(a, b)  # a + b 로도 쓸 수 있음\n",
        "print(c)\n",
        "\n",
        "# 위에서 변수와 수식들을 정의했지만, 실행이 정의한 시점에서 실행되는 것은 아닙니다.\n",
        "# 다음처럼 Session 객제와 run 메소드를 사용할 때 계산이 됩니다.\n",
        "# 따라서 모델을 구성하는 것과, 실행하는 것을 분리하여 프로그램을 깔끔하게 작성할 수 있습니다.\n",
        "# 그래프를 실행할 세션을 구성합니다.\n",
        "sess = tf.Session()\n",
        "# sess.run: 설정한 텐서 그래프(변수나 수식 등등)를 실행합니다.\n",
        "print(sess.run(hello))\n",
        "print(sess.run([a, b, c]))\n",
        "\n",
        "# 세션을 닫습니다.\n",
        "sess.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Tensor(\"Const:0\", shape=(), dtype=string)\n",
            "Tensor(\"Add:0\", shape=(), dtype=int32)\n",
            "b'Hello, TensorFlow!'\n",
            "[10, 32, 42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNpNxwXjbJ1o",
        "outputId": "6d20f37c-c8ae-4ae6-d2b4-51ddbdf532b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "# 플레이스홀더와 변수의 개념을 익혀봅니다\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# tf.placeholder: 계산을 실행할 때 입력값을 받는 변수로 사용합니다.\n",
        "# None 은 크기가 정해지지 않았음을 의미합니다.\n",
        "X = tf.placeholder(tf.float32, [None, 3])\n",
        "print(X)\n",
        "\n",
        "# X 플레이스홀더에 넣을 값 입니다.\n",
        "# 플레이스홀더에서 설정한 것 처럼, 두번째 차원의 요소의 갯수는 3개 입니다.\n",
        "x_data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "# tf.Variable: 그래프를 계산하면서 최적화 할 변수들입니다. 이 값이 바로 신경망을 좌우하는 값들입니다.\n",
        "# tf.random_normal: 각 변수들의 초기값을 정규분포 랜덤 값으로 초기화합니다.\n",
        "W = tf.Variable(tf.random_normal([3, 2]))\n",
        "b = tf.Variable(tf.random_normal([2, 1]))\n",
        "\n",
        "# 입력값과 변수들을 계산할 수식을 작성합니다.\n",
        "# tf.matmul 처럼 mat* 로 되어 있는 함수로 행렬 계산을 수행합니다.\n",
        "expr = tf.matmul(X, W) + b\n",
        "\n",
        "sess = tf.Session()\n",
        "# 위에서 설정한 Variable 들의 값들을 초기화 하기 위해\n",
        "# 처음에 tf.global_variables_initializer 를 한 번 실행해야 합니다.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print(\"=== x_data ===\")\n",
        "print(x_data)\n",
        "print(\"=== W ===\")\n",
        "print(sess.run(W))\n",
        "print(\"=== b ===\")\n",
        "print(sess.run(b))\n",
        "print(\"=== expr ===\")\n",
        "# expr 수식에는 X 라는 입력값이 필요합니다.\n",
        "# 따라서 expr 실행시에는 이 변수에 대한 실제 입력값을 다음처럼 넣어줘야합니다.\n",
        "print(sess.run(expr, feed_dict={X: x_data}))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n",
            "=== x_data ===\n",
            "[[1, 2, 3], [4, 5, 6]]\n",
            "=== W ===\n",
            "[[ 1.3020341   1.4945652 ]\n",
            " [-0.6535715   0.3170507 ]\n",
            " [-0.79951304  0.18839706]]\n",
            "=== b ===\n",
            "[[ 0.7809632]\n",
            " [-2.31759  ]]\n",
            "=== expr ===\n",
            "[[-1.6226847  3.474821 ]\n",
            " [-5.174389   6.3763075]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiWY0EV0bG5Q",
        "outputId": "bed8f82d-276d-4676-94e8-ef4724847f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# X 와 Y 의 상관관계를 분석하는 기초적인 선형 회귀 모델을 만들고 실행해봅니다.\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "x_data = [1, 2, 3]\n",
        "y_data = [1, 2, 3]\n",
        "\n",
        "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "\n",
        "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여줍니다.\n",
        "X = tf.placeholder(tf.float32, name=\"X\")\n",
        "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "# X 와 Y 의 상관 관계를 분석하기 위한 가설 수식을 작성합니다.\n",
        "# y = W * x + b\n",
        "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용했습니다.\n",
        "hypothesis = W * X + b\n",
        "\n",
        "# 손실 함수를 작성합니다.\n",
        "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정합니다.\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행합니다.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "# 비용을 최소화 하는 것이 최종 목표\n",
        "train_op = optimizer.minimize(cost)\n",
        "\n",
        "# 세션을 생성하고 초기화합니다.\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # 최적화를 100번 수행합니다.\n",
        "    for step in range(100):\n",
        "        # sess.run 을 통해 train_op 와 cost 그래프를 계산합니다.\n",
        "        # 이 때, 가설 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달합니다.\n",
        "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
        "\n",
        "        print(step, cost_val, sess.run(W), sess.run(b))\n",
        "\n",
        "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인해봅니다.\n",
        "    print(\"\\n=== Test ===\")\n",
        "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
        "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"X:0\", dtype=float32)\n",
            "Tensor(\"Y:0\", dtype=float32)\n",
            "0 2.2702546 [1.0327344] [0.09921141]\n",
            "1 0.027833944 [0.9624977] [0.06627536]\n",
            "2 0.0010138137 [0.9709897] [0.0680212]\n",
            "3 0.0006610759 [0.97085744] [0.06602107]\n",
            "4 0.0006260371 [0.97164875] [0.06447388]\n",
            "5 0.0005962576 [0.9723203] [0.06291959]\n",
            "6 0.00056793395 [0.9729868] [0.06140754]\n",
            "7 0.0005409553 [0.9736361] [0.0599313]\n",
            "8 0.000515263 [0.97426987] [0.0584906]\n",
            "9 0.0004907868 [0.97488844] [0.05708454]\n",
            "10 0.00046747155 [0.97549206] [0.05571224]\n",
            "11 0.00044526815 [0.9760812] [0.05437296]\n",
            "12 0.00042411542 [0.9766562] [0.05306588]\n",
            "13 0.0004039722 [0.97721744] [0.05179024]\n",
            "14 0.00038478212 [0.9777651] [0.05054522]\n",
            "15 0.00036650462 [0.97829956] [0.04933014]\n",
            "16 0.0003490957 [0.9788212] [0.04814428]\n",
            "17 0.0003325131 [0.97933036] [0.04698694]\n",
            "18 0.00031671798 [0.9798272] [0.0458574]\n",
            "19 0.0003016727 [0.98031217] [0.04475503]\n",
            "20 0.00028734506 [0.9807854] [0.04367915]\n",
            "21 0.00027369472 [0.98124737] [0.04262914]\n",
            "22 0.00026069515 [0.98169816] [0.04160436]\n",
            "23 0.0002483117 [0.98213816] [0.04060423]\n",
            "24 0.00023651734 [0.98256755] [0.03962813]\n",
            "25 0.0002252827 [0.9829866] [0.0386755]\n",
            "26 0.0002145805 [0.9833956] [0.03774575]\n",
            "27 0.00020438775 [0.98379475] [0.03683838]\n",
            "28 0.00019467948 [0.9841843] [0.0359528]\n",
            "29 0.00018543044 [0.9845645] [0.03508852]\n",
            "30 0.00017662346 [0.9849356] [0.03424504]\n",
            "31 0.00016823469 [0.9852977] [0.03342178]\n",
            "32 0.00016024268 [0.98565114] [0.03261836]\n",
            "33 0.00015263133 [0.98599607] [0.03183423]\n",
            "34 0.00014538095 [0.9863327] [0.03106897]\n",
            "35 0.00013847467 [0.98666126] [0.03032208]\n",
            "36 0.00013189831 [0.98698187] [0.02959315]\n",
            "37 0.00012563185 [0.98729485] [0.02888176]\n",
            "38 0.00011966457 [0.9876003] [0.02818748]\n",
            "39 0.00011398094 [0.98789835] [0.02750985]\n",
            "40 0.000108565844 [0.9881893] [0.02684853]\n",
            "41 0.00010340848 [0.9884732] [0.02620311]\n",
            "42 9.849784e-05 [0.9887503] [0.02557321]\n",
            "43 9.3817995e-05 [0.9890207] [0.02495846]\n",
            "44 8.936372e-05 [0.9892847] [0.0243585]\n",
            "45 8.511732e-05 [0.98954225] [0.02377294]\n",
            "46 8.107475e-05 [0.98979366] [0.02320145]\n",
            "47 7.722417e-05 [0.990039] [0.0226437]\n",
            "48 7.3554336e-05 [0.9902784] [0.02209934]\n",
            "49 7.0061906e-05 [0.9905122] [0.02156811]\n",
            "50 6.6733504e-05 [0.99074024] [0.02104961]\n",
            "51 6.356384e-05 [0.99096286] [0.0205436]\n",
            "52 6.0544535e-05 [0.9911801] [0.02004975]\n",
            "53 5.7668145e-05 [0.99139214] [0.01956776]\n",
            "54 5.4928783e-05 [0.991599] [0.01909736]\n",
            "55 5.2320534e-05 [0.991801] [0.01863827]\n",
            "56 4.983413e-05 [0.9919981] [0.0181902]\n",
            "57 4.746755e-05 [0.9921905] [0.01775295]\n",
            "58 4.5212702e-05 [0.9923782] [0.01732616]\n",
            "59 4.3065582e-05 [0.9925614] [0.01690966]\n",
            "60 4.101948e-05 [0.9927402] [0.01650316]\n",
            "61 3.907101e-05 [0.99291474] [0.01610644]\n",
            "62 3.721509e-05 [0.9930851] [0.01571926]\n",
            "63 3.544769e-05 [0.9932513] [0.01534138]\n",
            "64 3.3763845e-05 [0.99341357] [0.01497259]\n",
            "65 3.2159038e-05 [0.9935718] [0.01461262]\n",
            "66 3.0631658e-05 [0.9937264] [0.01426137]\n",
            "67 2.917652e-05 [0.9938772] [0.01391852]\n",
            "68 2.7790933e-05 [0.99402434] [0.01358393]\n",
            "69 2.6471253e-05 [0.99416804] [0.0132574]\n",
            "70 2.521342e-05 [0.99430823] [0.01293869]\n",
            "71 2.4016132e-05 [0.994445] [0.01262765]\n",
            "72 2.287566e-05 [0.9945786] [0.01232411]\n",
            "73 2.1788619e-05 [0.99470896] [0.01202785]\n",
            "74 2.0753878e-05 [0.99483615] [0.01173872]\n",
            "75 1.9767513e-05 [0.99496025] [0.01145651]\n",
            "76 1.8829332e-05 [0.9950814] [0.0111811]\n",
            "77 1.7934499e-05 [0.9951996] [0.01091231]\n",
            "78 1.708267e-05 [0.995315] [0.01064999]\n",
            "79 1.6271466e-05 [0.99542767] [0.01039399]\n",
            "80 1.5498097e-05 [0.9955375] [0.01014412]\n",
            "81 1.4761997e-05 [0.9956448] [0.00990027]\n",
            "82 1.4060665e-05 [0.99574953] [0.00966229]\n",
            "83 1.33928625e-05 [0.9958517] [0.00943001]\n",
            "84 1.2757127e-05 [0.9959515] [0.00920333]\n",
            "85 1.2150714e-05 [0.99604875] [0.00898206]\n",
            "86 1.1573565e-05 [0.9961437] [0.00876614]\n",
            "87 1.1024276e-05 [0.99623644] [0.00855543]\n",
            "88 1.0500087e-05 [0.9963269] [0.00834976]\n",
            "89 1.000172e-05 [0.99641526] [0.00814905]\n",
            "90 9.526087e-06 [0.9965013] [0.00795312]\n",
            "91 9.0742715e-06 [0.9965855] [0.00776197]\n",
            "92 8.642758e-06 [0.99666756] [0.00757537]\n",
            "93 8.232588e-06 [0.99674773] [0.00739328]\n",
            "94 7.841177e-06 [0.9968259] [0.00721553]\n",
            "95 7.4691575e-06 [0.99690217] [0.00704207]\n",
            "96 7.114146e-06 [0.9969766] [0.00687278]\n",
            "97 6.7760775e-06 [0.9970493] [0.00670757]\n",
            "98 6.4543806e-06 [0.99712026] [0.00654634]\n",
            "99 6.14808e-06 [0.9971895] [0.00638898]\n",
            "\n",
            "=== Test ===\n",
            "X: 5, Y: [4.9923368]\n",
            "X: 2.5, Y: [2.4993627]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}